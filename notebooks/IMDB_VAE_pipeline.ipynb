{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qADDiiIgCql"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "i3wUjdjLg0fW",
    "outputId": "b57778fd-bdb3-4ebf-bc9d-a5f33987f7e1"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = \"twitter.27B.50d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \".\".join(pretrained.split('.')[:2])\n",
    "dim = int(pretrained.split('.')[-1].replace('d',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "from datasets import imdb as dataset\n",
    "import TextCNN.models.textcnn as textcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'rt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'imdb':\n",
    "    dataset.split_train_valid(path_data='/ksozykinraid/data/nlp/IMDB/imdb.csv')\n",
    "    pth = torch.load('/ksozykinraid/data/nlp/IMDB/imdb_text_cnn_best_twitter27b50d.pth',map_location='cpu')\n",
    "elif dataset_name == 'rt':\n",
    "    dataset.split_train_valid(path_data='/ksozykinraid/data/nlp/rt-polaritydata/rt-polarity.csv')\n",
    "    pth = torch.load('/ksozykinraid/data/nlp/rt-polaritydata/rt-polarity_twitter.27B.50d_text_cnn_best.pth',map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_length=32\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.IMDB_Dataset(pretrained=pretrained,fix_length=fix_length,mbsize=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = dataset.TEXT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = textcnn.textCNN(V, 100, [3,4,5], 0.5 , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.load_state_dict(pth['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.embed = feedEmbed(target.embed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "disc = textcnn.textCNN(V, 100, [3,4,5], 0.5 , 2)\n",
    "disc.embed = target.embed \n",
    "disc = disc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_all_grads(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyRyRECbjRH1"
   },
   "outputs": [],
   "source": [
    "#model.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('pth/'):\n",
    "    os.makedirs('pth/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = dataset.LABEL.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dim = 32\n",
    "lr = 1e-2\n",
    "lr_decay_every = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.n_train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = RNN_VAE(\n",
    "    dataset.n_vocab, h_dim,h_dim,2, p_word_dropout=0.3,\n",
    "    pretrained_embeddings=dataset.get_vocab_vectors(), freeze_embeddings=False,max_sent_len=fix_length,\n",
    "    gpu=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_itos(x):\n",
    "    return [\" \".join([V.itos[e] for e in s]) for s in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(p):\n",
    "    # [seq_len,probs]\n",
    "    # per 1 elem in batch\n",
    "    # as in paper\n",
    "    with torch.no_grad():\n",
    "        #ppl = -torch.log(F.softmax(p,-1)).sum(1).sum(0)/len(V)\n",
    "        ppl = -F.log_softmax(p,-1).sum(1).sum(0)/len(V)\n",
    "        return ppl.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,phi):\n",
    "    pth = {}\n",
    "    pth['state_dict'] = model.state_dict()\n",
    "    torch.save(pth, 'pth/vae_phi{}.pth'.format(phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_attack_rate(N):\n",
    "    j = 0\n",
    "    rate = []\n",
    "    perp = []\n",
    "    for _ in range(N):\n",
    "        z = model.sample_z_prior(1)\n",
    "        c = model.sample_c_prior(1)\n",
    "        z=torch.cat([z,model.C[torch.argmax(c)].unsqueeze(0)],-1)\n",
    "\n",
    "\n",
    "        sample_idxs,sample_logits = model.sample_sentence(z, c)\n",
    "        sample_sent = dataset.idxs2sentence(sample_idxs)\n",
    "        ppl = perplexity(sample_logits)\n",
    "        sample_logits = sample_logits.unsqueeze(0)\n",
    "\n",
    "\n",
    "        if sample_logits.shape[1] < 5:\n",
    "            continue\n",
    "        j += 1\n",
    "        if j >= N:\n",
    "            break\n",
    "        c_idx = torch.argmax(c,-1).cpu().numpy()[0]\n",
    "        pred_label_idx =  torch.argmax(target(sample_logits),-1)[0].cpu().numpy()\n",
    "        rate.append(c_idx !=  pred_label_idx)\n",
    "        perp.append(ppl)\n",
    "    perp = np.mean(ppl)\n",
    "    attack_rate=np.mean(rate)\n",
    "    return attack_rate,perp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_disriminator = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(phi = 0,\n",
    "          num_epochs=5,\n",
    "          log_interval = 10,\n",
    "          gen_batch_size=8):\n",
    "    vanila = (phi == 0)\n",
    "    print(\"phi={}\".format(phi))\n",
    "    n_iter = num_epochs*dataset.n_train_batch\n",
    "    # Annealing for KL term\n",
    "    kld_start_inc = 1000\n",
    "    kld_weight = 0.0\n",
    "    kld_max = 1\n",
    "    kld_inc = (kld_max - kld_weight) / (n_iter - kld_start_inc)\n",
    "    it = 0\n",
    "    loss_data = []\n",
    "    recon_loss_data = []\n",
    "    kl_loss_data = []\n",
    "    opt = optim.Adam(model.vae_params + list(target.parameters()), lr=lr)\n",
    "    opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "      #print(\"epoch\",epoch)\n",
    "      for idx,batch in enumerate(dataset.train_iter):\n",
    "            x, labels = batch.text, batch.label\n",
    "            c  = torch.eye(2)[labels]\n",
    "            x, labels = x.to(device), labels.to(device)\n",
    "            c = c.to(device)\n",
    "\n",
    "            recon_loss, kl_loss, x_hat = model.forward(x,c)\n",
    "            loss = recon_loss + kld_weight * kl_loss\n",
    "\n",
    "\n",
    "            #Anneal kl_weight\n",
    "            if it > kld_start_inc and kld_weight < kld_max:\n",
    "                kld_weight += kld_inc\n",
    "\n",
    "            loss = loss.reshape(1)\n",
    "            attack_rate = 0\n",
    "\n",
    "            if not vanila:\n",
    "                x_adv, labels_adv = model.generate_sentences(gen_batch_size)\n",
    "                pred_adv = target(x_adv)\n",
    "                Ladv = F.cross_entropy(pred_adv,torch.argmax(labels_adv.long(),-1))\n",
    "\n",
    "                labels_adv_idx =  torch.argmax(labels_adv.long(),-1).cpu().numpy()\n",
    "                pred_label_idx =  torch.argmax(pred_adv,-1).cpu().numpy()\n",
    "\n",
    "                attack_rate=np.mean((labels_adv_idx !=  pred_label_idx))\n",
    "                \n",
    "                loss -= phi*Ladv\n",
    "                \n",
    "                if with_disriminator:\n",
    "                    x_real = torch.eye(len(V))[x].to(device)\n",
    "                    x_real = torch.transpose(x_real,0, 1)\n",
    "                    pred_real = disc(x_real)\n",
    "                    Ldisc_real = F.cross_entropy(pred_real,labels)\n",
    "                    Ldisc_real.backward()\n",
    "                    #https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "                    pred_fake = disc(x_adv.detach())\n",
    "                    Ldisc_fake = F.cross_entropy(pred_fake,torch.argmax(labels_adv.long(),-1))\n",
    "                    Ldisc_fake.backward()\n",
    "                    \n",
    "                    Ldisc = Ldisc_real + Ldisc_fake\n",
    "                    grad_norm = torch.nn.utils.clip_grad_norm(disc.parameters(), 1)\n",
    "                    opt_disc.step()\n",
    "                    opt_disc.zero_grad()\n",
    "                    \n",
    "                \n",
    "                #print('loss',loss.data)\n",
    "\n",
    "            loss.backward()\n",
    "            #grad_norm = torch.nn.utils.clip_grad_norm(model.vae_params, 1)\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            loss_data.append(loss.data)\n",
    "            recon_loss_data.append(recon_loss.reshape(1).data)\n",
    "            kl_loss_data.append(kl_loss.reshape(1).data)\n",
    "\n",
    "\n",
    "            if it % log_interval == 0:\n",
    "\n",
    "                save_model(model,phi)\n",
    "                x_text = batch_itos(x)\n",
    "                x_text_hat = batch_itos(torch.argmax(x_hat,-1))\n",
    "\n",
    "                z = model.sample_z_prior(1)\n",
    "                c = model.sample_c_prior(1)\n",
    "                z=torch.cat([z,model.C[torch.argmax(c)].unsqueeze(0)],-1)\n",
    "\n",
    "                sample_idxs,sample_logits = model.sample_sentence(z, c)\n",
    "                sample_sent = dataset.idxs2sentence(sample_idxs)\n",
    "\n",
    "                sample_logits = sample_logits.unsqueeze(0)\n",
    "\n",
    "\n",
    "                if sample_logits.shape[1] < 5:\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "                pred_label_idx =  torch.argmax(target(sample_logits),-1)[0]\n",
    "\n",
    "\n",
    "                c_idx = torch.argmax(c)\n",
    "                print('epoch-%d Iter-%d; Loss: %9.4f; Recon: %9.4f; KL: %9.4f;'%(epoch,it, loss.data, \n",
    "                                                                                 recon_loss.data, kl_loss.data))\n",
    "                print(sample_sent)\n",
    "                print('sampled',itos[c_idx],'predicted',itos[pred_label_idx])\n",
    "                print('attack_rate per batch',attack_rate)\n",
    "                print('perplexity per sampled sentance',perplexity(sample_logits[0]))\n",
    "                print()\n",
    "            # Anneal learning rate\n",
    "            #new_lr = lr * (0.5 ** (it // lr_decay_every))\n",
    "            #for param_group in opt.param_groups:\n",
    "            #    param_group['lr'] = new_lr\n",
    "            it += 1\n",
    "    \n",
    "    return loss_data,recon_loss_data, kl_loss_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval =  1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_data,recon_loss_data, kl_loss_data = train(phi=0,num_epochs=250,log_interval = log_interval)\n",
    "a,ppl = test_attack_rate(500)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LD = []\n",
    "RLD = []\n",
    "KLD = []\n",
    "for i in range(0, len(loss_data)):\n",
    "    LD.append(loss_data[i].data.cpu().numpy()[0])\n",
    "    RLD.append(recon_loss_data[i].data.cpu().numpy()[0])\n",
    "    KLD.append(kl_loss_data[i].data.cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(LD, marker='o',label='LD')\n",
    "plt.plot(RLD, marker='o',label='RLD')\n",
    "plt.plot(KLD, marker='o',label='KLD')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "phis=[1,3,6,9]\n",
    "for phi in phis:\n",
    "    vae_phi0_pth = torch.load('./pth/vae_phi0.pth',map_location='cpu')\n",
    "    model.load_state_dict(vae_phi0_pth['state_dict'])\n",
    "    log_interval = 10\n",
    "    num_epochs = 3\n",
    "    loss_data,recon_loss_data, kl_loss_data = train(phi=phi,num_epochs=num_epochs,log_interval = log_interval)\n",
    "    a,ppl = test_attack_rate(100)\n",
    "    print('test attack rate',a)\n",
    "    print('test ppl',ppl)\n",
    "    #attack_rates_test.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phis=[0,1,3,6,9]\n",
    "at = []\n",
    "perp = []\n",
    "for phi in phis:\n",
    "    print(phi)\n",
    "    vae_phi0_pth = torch.load('./pth/vae_phi{}.pth'.format(phi),map_location='cpu')\n",
    "    model.load_state_dict(vae_phi0_pth['state_dict'])\n",
    "    a,ppl = test_attack_rate(1000)\n",
    "    print('test attack rate',a)\n",
    "    print('test ppl',ppl)\n",
    "    perp.append(ppl)\n",
    "    at.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(phis,at,marker='o',color='red')\n",
    "plt.grid()\n",
    "plt.xlabel(\"phi\")\n",
    "plt.ylabel(\"attack rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor='white')\n",
    "plt.plot(phis,perp,marker='o',color='g')\n",
    "plt.grid()\n",
    "plt.xlabel(\"phi\")\n",
    "plt.ylabel(\"ppl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IMDB_VAE_pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
